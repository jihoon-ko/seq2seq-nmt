{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "link = 'http://m.endic.naver.com/example.nhn?sLn=kr&exampleId=%s&webCrawl=0'\n",
    "link_n = 6540\n",
    "\n",
    "data = []\n",
    "\n",
    "\n",
    "for i in range(link_n):\n",
    "    url = link % (i+1)\n",
    "    response = requests.get(url).text\n",
    "    soup = BeautifulSoup(response, 'html.parser')\n",
    "    korean = str(soup.find_all(class_=\"text_wrap\")[0])[24:-7]\n",
    "    eng = str(soup.find_all(class_=\"cp_trans_area\")[0])[27:-6]\n",
    "    if i % 10 == 0:\n",
    "        print((korean, eng))\n",
    "        with open('data.txt', 'w') as outfile:\n",
    "            json.dump(data, outfile)\n",
    "    data.append((korean, eng))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "data = json.load(open(\"data.txt\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1730\n",
      "['how', 'are', 'you', 'doing', '?']\n"
     ]
    }
   ],
   "source": [
    "N = len(data)\n",
    "print(N)\n",
    "kor, eng = [], []\n",
    "for x in data:\n",
    "    kor.append(x[0])\n",
    "    _eng = []\n",
    "    for word in x[1].split():\n",
    "        word = word.lower()\n",
    "        punc = None\n",
    "        if len(word) > 1:\n",
    "            if ord(word[-1]) < ord('a') or ord(word[-1]) > ord('z'):\n",
    "                punc = word[-1]\n",
    "                word = word[:-1]\n",
    "        _eng.append(word)\n",
    "        if punc: _eng.append(punc)\n",
    "    eng.append(_eng)\n",
    "\n",
    "print(eng[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l_enc:  45\n",
      "l_dec:  18\n",
      "m_enc:  730\n",
      "m_dec:  1463\n"
     ]
    }
   ],
   "source": [
    "dec_wtoi = {}\n",
    "dec_itow = []\n",
    "m_dec = 0\n",
    "\n",
    "enc_wtoi = {}\n",
    "enc_itow = []\n",
    "m_enc = 0\n",
    "\n",
    "l_enc = 0\n",
    "\n",
    "\n",
    "for words in kor:\n",
    "    cnt = 0\n",
    "    l_enc = max(l_enc, len(words))\n",
    "    for char in words:\n",
    "        if char not in enc_wtoi:\n",
    "            enc_wtoi[char] = m_enc\n",
    "            enc_itow.append(char)\n",
    "            m_enc += 1\n",
    "    \n",
    "enc_wtoi[' '] = m_enc\n",
    "enc_itow.append(' ')\n",
    "\n",
    "dec_wtoi['<START>'] = m_dec\n",
    "dec_itow.append('<START>')\n",
    "m_dec += 1\n",
    "\n",
    "l_dec = 0\n",
    "for words in eng:\n",
    "    l_dec = max(l_dec, len(words))\n",
    "    for word in words:\n",
    "        if word not in dec_wtoi:\n",
    "            dec_wtoi[word] = m_dec\n",
    "            dec_itow.append(word)\n",
    "            m_dec += 1\n",
    "        \n",
    "dec_wtoi['<END>'] = m_dec\n",
    "dec_itow.append('<END>')\n",
    "m_dec += 1\n",
    "\n",
    "print (\"l_enc: \", l_enc)\n",
    "print (\"l_dec: \", l_dec)\n",
    "print (\"m_enc: \", m_enc)\n",
    "print (\"m_dec: \", m_dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[730. 730. 730. ...   2.   1.   0.]\n",
      " [730. 730. 730. ...  10.   4.   9.]\n",
      " [730. 730. 730. ...  19.  18.  17.]\n",
      " ...\n",
      " [730. 730. 730. ... 170. 224.   0.]\n",
      " [730. 730. 730. ...  84.  22.  47.]\n",
      " [730. 730. 730. ...  18. 177. 333.]]\n",
      "[[0.000e+00 1.000e+00 2.000e+00 ... 1.462e+03 1.462e+03 1.462e+03]\n",
      " [0.000e+00 6.000e+00 7.000e+00 ... 1.462e+03 1.462e+03 1.462e+03]\n",
      " [0.000e+00 1.200e+01 1.300e+01 ... 1.462e+03 1.462e+03 1.462e+03]\n",
      " ...\n",
      " [0.000e+00 2.240e+02 1.690e+02 ... 1.462e+03 1.462e+03 1.462e+03]\n",
      " [0.000e+00 3.950e+02 3.500e+01 ... 1.462e+03 1.462e+03 1.462e+03]\n",
      " [0.000e+00 2.450e+02 4.700e+01 ... 1.462e+03 1.462e+03 1.462e+03]]\n",
      "[[1.000e+00 2.000e+00 3.000e+00 ... 1.462e+03 1.462e+03 1.462e+03]\n",
      " [6.000e+00 7.000e+00 8.000e+00 ... 1.462e+03 1.462e+03 1.462e+03]\n",
      " [1.200e+01 1.300e+01 1.400e+01 ... 1.462e+03 1.462e+03 1.462e+03]\n",
      " ...\n",
      " [2.240e+02 1.690e+02 3.000e+00 ... 1.462e+03 1.462e+03 1.462e+03]\n",
      " [3.950e+02 3.500e+01 1.188e+03 ... 1.462e+03 1.462e+03 1.462e+03]\n",
      " [2.450e+02 4.700e+01 1.700e+01 ... 1.462e+03 1.462e+03 1.462e+03]]\n"
     ]
    }
   ],
   "source": [
    "X_enc_train = m_enc * np.ones((N, l_enc))\n",
    "X_dec_train = (m_dec - 1) * np.ones((N, l_dec+1))\n",
    "y_train = (m_dec - 1) * np.ones((N, l_dec+1))\n",
    "for i, word in enumerate(kor):\n",
    "    cnt = 0\n",
    "    for j, char in enumerate(word):\n",
    "        if char == ' ': continue\n",
    "        cnt += 1\n",
    "        X_enc_train[i, l_enc-cnt] = enc_wtoi[char]\n",
    "\n",
    "for i, words in enumerate(eng):\n",
    "    X_dec_train[i][0] = 0\n",
    "    for j, word in enumerate(words):\n",
    "        X_dec_train[i, j+1] = y_train[i, j] = dec_wtoi[word]\n",
    "\n",
    "print(X_enc_train)\n",
    "print(X_dec_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, ?, 1463)\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "n_hidden = 200\n",
    "total_epoch = 100\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "X_enc = tf.placeholder(tf.int32, [None, l_enc])\n",
    "X_dec = tf.placeholder(tf.int32, [None, None])\n",
    "y = tf.placeholder(tf.int32, [None, None])\n",
    "is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "def model(X_enc, X_dec, is_training):\n",
    "    keep_prob = tf.cond(is_training, lambda:tf.constant(0.5), lambda:tf.constant(1.0))\n",
    "    if is_training is not None:\n",
    "        trainable = True\n",
    "    else:\n",
    "        trainable = False\n",
    "    embedding_enc = tf.get_variable('embedding_enc', initializer=tf.random_uniform([m_enc, n_hidden], -1.0, 1.0), trainable=trainable)\n",
    "    mt = tf.get_variable('mt', shape=[1, n_hidden], initializer=tf.zeros_initializer(), trainable=False, dtype=tf.float32)\n",
    "    embedding_enc = tf.concat([embedding_enc, mt], 0, name='concatt')\n",
    "    embedding_dec = tf.get_variable('embedding_dec', initializer=tf.random_uniform([m_dec, n_hidden], -1.0, 1.0), trainable=trainable)\n",
    "    after_embedding_enc = tf.cast(tf.nn.embedding_lookup(embedding_enc, X_enc, validate_indices=False), tf.float32)\n",
    "    after_embedding_dec = tf.cast(tf.nn.embedding_lookup(embedding_dec, X_dec, validate_indices=False), tf.float32)\n",
    "    \n",
    "    inputs = tf.layers.conv2d(inputs=tf.reshape(after_embedding_enc, [-1, l_enc, n_hidden, 1]),\n",
    "                              filters=1,\n",
    "                              kernel_size=(1, 5),\n",
    "                              trainable=trainable)\n",
    "    \n",
    "    with tf.variable_scope('encode'):\n",
    "        enc_cell = tf.nn.rnn_cell.BasicLSTMCell(n_hidden)\n",
    "        enc_cell = tf.nn.rnn_cell.DropoutWrapper(enc_cell, output_keep_prob=keep_prob)\n",
    "        outputs, enc_states = tf.nn.dynamic_rnn(enc_cell, after_embedding_enc, dtype=tf.float32)\n",
    "    \n",
    "    with tf.variable_scope('decode'):\n",
    "        dec_cell = tf.nn.rnn_cell.BasicLSTMCell(n_hidden)\n",
    "        dec_cell = tf.nn.rnn_cell.DropoutWrapper(dec_cell, output_keep_prob=keep_prob)\n",
    "        outputs, dec_states = tf.nn.dynamic_rnn(dec_cell, after_embedding_dec, initial_state=enc_states, dtype=tf.float32)\n",
    "    \n",
    "    out = tf.layers.dense(outputs, n_hidden, activation=None, trainable=trainable)\n",
    "    out = tf.tensordot(out, embedding_dec, axes=[[2], [1]])\n",
    "    print(out.get_shape())\n",
    "    return out\n",
    "\n",
    "y_out = model(X_enc, X_dec, is_training)\n",
    "cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y_out, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #82\n",
      "loss: 0.10514888\n",
      "val_loss: 0.038490854\n",
      " input:  그밖에 달리 설명할 방법이 없어요.\n",
      "answer:  i can't explain it in any other way .\n",
      " model:  i can't explain it in any other way .\n",
      "\n",
      " input:  어서 오십시오.\n",
      "answer:  hello , may i help you ?\n",
      " model:  hello . may i help you ?\n",
      "\n",
      " input:  그것은 견해상의 문제입니다.\n",
      "answer:  it's a matter of opinion .\n",
      " model:  it's a matter of opinion .\n",
      "\n",
      " input:  그 계획에 찬성합니다.\n",
      "answer:  i agree with the plan .\n",
      " model:  i agree with the plan .\n",
      "\n",
      "correct:  171\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-140-42ae8f372463>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m                      y: y_train[rng]}\n\u001b[0;32m     30\u001b[0m         \u001b[0mth\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m         \u001b[0mstp\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jihoon\\appdata\\local\\conda\\conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jihoon\\appdata\\local\\conda\\conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1126\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1128\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1129\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jihoon\\appdata\\local\\conda\\conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1342\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1344\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1345\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1346\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jihoon\\appdata\\local\\conda\\conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1348\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1351\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jihoon\\appdata\\local\\conda\\conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1329\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1331\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "import random\n",
    "\n",
    "batch_size = 128\n",
    "test_num = 200\n",
    "N_ = N - test_num\n",
    "\n",
    "indices = np.arange(N)\n",
    "np.random.shuffle(indices)\n",
    "test_indices = indices[-test_num:]\n",
    "train_indices = indices[:-test_num]\n",
    "\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "stp = 0\n",
    "best_counter = 0\n",
    "for epoch in range(1000):\n",
    "    epoch_indices = np.arange(N_)\n",
    "    np.random.shuffle(epoch_indices)\n",
    "    th = 0\n",
    "    while th < N_:\n",
    "        rng = train_indices[epoch_indices[th:min(th+batch_size, N_)]]\n",
    "        feed_dict = {X_enc: X_enc_train[rng],\n",
    "                     X_dec: X_dec_train[rng],\n",
    "                     is_training: True,\n",
    "                     y: y_train[rng]}\n",
    "        th += batch_size\n",
    "        loss, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        stp += 1\n",
    "        \n",
    "    clear_output()\n",
    "    print ('Epoch #%d' % (epoch+1))\n",
    "    print ('loss:', loss)\n",
    "    y_now = np.zeros((test_num, 1))\n",
    "    rng = test_indices[:]\n",
    "    for i in range(1, l_dec):\n",
    "        feed_dict = {X_enc: X_enc_train[rng],\n",
    "                     X_dec: X_dec_train[rng],\n",
    "                     is_training: False}\n",
    "        res = np.array(sess.run(y_out, feed_dict=feed_dict))\n",
    "        y_now = np.argmax(res, axis=2)\n",
    "        \n",
    "    feed_dict = {X_enc: X_enc_train[rng],\n",
    "                 X_dec: X_dec_train[rng],\n",
    "                 y: y_train[rng],\n",
    "                 is_training: False}\n",
    "    loss, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "    print ('val_loss:', loss)\n",
    "    \n",
    "    correct = 0\n",
    "    for ii in range(test_num):\n",
    "        i = test_indices[ii]\n",
    "        import random\n",
    "        print_mode = random.random() < 0.025\n",
    "        if print_mode:\n",
    "            print (\" input: \", kor[i])\n",
    "            print (\"answer: \", \" \".join(eng[i]))\n",
    "            print (\" model: \", end=\" \")\n",
    "        model_answer = []\n",
    "        for j in range(l_dec):\n",
    "            if y_now[ii, j] == m_dec - 1:\n",
    "                break\n",
    "            model_answer.append(dec_itow[y_now[ii, j]])\n",
    "        model_answer = \" \".join(model_answer)\n",
    "        if model_answer == \" \".join(eng[i]):\n",
    "            correct += 1\n",
    "        if print_mode:\n",
    "            print(model_answer, end='\\n\\n')\n",
    "    print(\"correct: \", correct)\n",
    "    if correct >= best_counter:\n",
    "        best_counter = correct\n",
    "        saver.save(sess, \"./model.ckpt\")\n",
    "        \n",
    "    \"\"\"\n",
    "    for ii in range(200):\n",
    "        i = np.random.randint(0, N)\n",
    "        print (\" input: \", kor[i])\n",
    "        print (\"answer: \", \" \".join(eng[i]))\n",
    "        print (\" model: \", end=\" \")\n",
    "        y_now = [0]\n",
    "        model_answer = []\n",
    "        for j in range(l_dec):\n",
    "            res = np.array(sess.run(y_out, feed_dict={X_enc: X_enc_train[i:i+1],\n",
    "                                                      X_dec: np.array([y_now]),\n",
    "                                                      is_training: False}))\n",
    "            best_word_idx = np.argmax(res[0][j])\n",
    "            y_now.append(best_word_idx)\n",
    "            if best_word_idx == m_dec - 1:\n",
    "                break\n",
    "            model_answer.append(dec_itow[np.argmax(res[0][j])])\n",
    "        model_answer = \" \".join(model_answer)\n",
    "        if model_answer == \" \".join(eng[i]):\n",
    "            model_answer += ' <- and the answer is correct!'\n",
    "        print(model_answer, end='\\n\\n')\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_translate(sentence):\n",
    "    X_test = m_enc * np.ones((1, l_enc))\n",
    "    cnt = 0\n",
    "    for char in sentence:\n",
    "        if char == ' ' or char not in enc_wtoi: continue\n",
    "        cnt += 1\n",
    "        X_test[0, l_enc-cnt] = enc_wtoi[char]\n",
    "    # print(X_test)\n",
    "    y_now = [0]\n",
    "    model_answer = []\n",
    "    for j in range(l_dec):\n",
    "        res = np.array(sess.run(y_out, feed_dict={X_enc: X_test,\n",
    "                                                  X_dec: np.array([y_now]),\n",
    "                                                  is_training: False}))\n",
    "        best_word_idx = np.argmax(res[0][j])\n",
    "        y_now.append(best_word_idx)\n",
    "        if best_word_idx == m_dec - 1:\n",
    "            break\n",
    "        model_answer.append(dec_itow[np.argmax(res[0][j])])\n",
    "    model_answer = \" \".join(model_answer)\n",
    "    print(model_answer, end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we walk ?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "do_translate(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch #33\n",
    "loss: 0.5201072\n",
    "val_loss: 0.38887665\n",
    " input:  좋습니다. 참 좋은 생각이에요.\n",
    "answer:  o.k . that's a good idea .\n",
    " model:  that's . i a good idea .\n",
    "\n",
    " input:  제 차를 다 고쳤습니까?\n",
    "answer:  is my car ready to go ?\n",
    " model:  is my car to to go ?\n",
    "\n",
    " input:  당신 차 좀 사용할 수 있을까요?\n",
    "answer:  do you think i could use your car ?\n",
    " model:  can you i i ask your your car ?\n",
    "\n",
    " input:  김씨를 소개하겠습니다.\n",
    "answer:  may i introduce mr . kim to you ?\n",
    " model:  may i introduce . . kim your you ?\n",
    "\n",
    " input:  현재 위치를 가르쳐 주세요.\n",
    "answer:  please point out where i am on this map .\n",
    " model:  please get out on i am on this . .\n",
    "\n",
    " input:  아주 좋은 날씨야.\n",
    "answer:  what a beautiful day !\n",
    " model:  what a nice day .\n",
    "\n",
    "correct:  45"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch #35\n",
    "loss: 0.41394392\n",
    "val_loss: 0.32920885\n",
    " input:  제발 나 그만 웃기세요.\n",
    "answer:  don't make me laugh , please .\n",
    " model:  don't make me at . please .\n",
    "\n",
    " input:  여름에는 비가 많이 옵니다.\n",
    "answer:  it rains a lot in summer .\n",
    " model:  it rains is lot in summer .\n",
    "\n",
    "correct:  50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch #36\n",
    "loss: 0.40963733\n",
    "val_loss: 0.3046625\n",
    " input:  어디가 제일 좋을까요?\n",
    "answer:  what is the best place to go ?\n",
    " model:  what is the best place to go ?\n",
    "\n",
    " input:  가능하시다면 편지주세요.\n",
    "answer:  perhaps you could write to me .\n",
    " model:  please you could write to me .\n",
    "\n",
    " input:  비가 쏟아질 것 같습니다.\n",
    "answer:  it threatens to rain .\n",
    " model:  it looks to rain .\n",
    "\n",
    " input:  여기서 시내로 연결되는 버스가 있습니까?\n",
    "answer:  is there a bus that goes to downtown from here ?\n",
    " model:  is there a bus that downtown to hear from here ?\n",
    "\n",
    " input:  당신이 어떻게 나한테 그렇게 말할 수 있어요?\n",
    "answer:  why could you take to me like that ?\n",
    " model:  why could you take your me ? that ?\n",
    "\n",
    " input:  시내까지는 몇 정거장을 가야 합니까?\n",
    "answer:  how many stops are we from downtown ?\n",
    " model:  how many stops are we be here ?\n",
    "\n",
    " input:  끼여들지 마세요!\n",
    "answer:  don't cut in !\n",
    " model:  don't in in !\n",
    "\n",
    " input:  여기서 뉴욕역까진 시간이 얼마나 걸립니까?\n",
    "answer:  how long will it take to get to new york station from here ?\n",
    " model:  how long will it take to get to new york station from here ?\n",
    "\n",
    " input:  당신에게 솔직하게 얘기하고 있어요.\n",
    "answer:  i'm being very honest with you .\n",
    " model:  i'm being very honest with you .\n",
    "\n",
    "correct:  63"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "poch #38\n",
    "loss: 0.33438048\n",
    "val_loss: 0.2540911\n",
    " input:  좋습니다. 참 좋은 생각이에요.\n",
    "answer:  o.k . that's a good idea .\n",
    " model:  that's . that's a good idea .\n",
    "\n",
    " input:  힘 내시고, 다음 번에 다시 해 보세요.\n",
    "answer:  come on , try it again .\n",
    " model:  come on , the it , .\n",
    "\n",
    " input:  무슨 일입니까?\n",
    "answer:  what's up ?\n",
    " model:  what's up ?\n",
    "\n",
    " input:  그럼, 다음에 또 뵐게요. 안녕히 계세요.\n",
    "answer:  well , see you later . good bye .\n",
    " model:  well , see you later . good bye .\n",
    "\n",
    "correct:  69"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch #39\n",
    "loss: 0.38782102\n",
    "val_loss: 0.23249874\n",
    " input:  최소한 사과는 할 수 있잖아요?\n",
    "answer:  you might at least apologize .\n",
    " model:  you might at least apologize .\n",
    "\n",
    " input:  발 디딜 틈도 없군요.\n",
    "answer:  there's no place to put my feet .\n",
    " model:  there's no place to put my feet .\n",
    "\n",
    " input:  현재 위치를 가르쳐 주세요.\n",
    "answer:  please point out where i am on this map .\n",
    " model:  please point out on i am on this map .\n",
    "\n",
    " input:  그게 어쨌단 말이에요?\n",
    "answer:  what about it ?\n",
    " model:  what about it ?\n",
    "\n",
    " input:  흥분하지 말아요.\n",
    "answer:  don't get mad .\n",
    " model:  don't get mad .\n",
    "\n",
    " input:  진실은 언젠가 드러나는 거예요.\n",
    "answer:  the truth will come out .\n",
    " model:  the truth will come out .\n",
    "\n",
    " input:  불쾌한 날씨죠?\n",
    "answer:  nasty weather , isn't it ?\n",
    " model:  nasty weather , isn't it ?\n",
    "\n",
    " input:  화내지 마세요.\n",
    "answer:  please don't lose your temper .\n",
    " model:  don't don't angry get temper .\n",
    "\n",
    "correct:  96"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch #43\n",
    "loss: 0.28099942\n",
    "val_loss: 0.16527152\n",
    " input:  여기서 내려 주세요.\n",
    "answer:  let me off here , please .\n",
    " model:  let me off here , please .\n",
    "\n",
    " input:  어디가는 길이세요?\n",
    "answer:  where are you headed ?\n",
    " model:  where are you headed ?\n",
    "\n",
    " input:  진정하세요!\n",
    "answer:  slow down !\n",
    " model:  simmer down !\n",
    "\n",
    " input:  뉴욕행 열차 보통석으로 왕복권을 사고 싶습니다.\n",
    "answer:  i'd like to buy a second class , round-trip ticket to new york .\n",
    " model:  i'd like to buy a second class , round-trip to to new york .\n",
    "\n",
    " input:  아주 좋은 날씨야.\n",
    "answer:  what a beautiful day !\n",
    " model:  what a nice day .\n",
    "\n",
    " input:  좀 도와 주시겠어요?\n",
    "answer:  would you mind helping me ?\n",
    " model:  could you mind helping me ?\n",
    "\n",
    "correct:  126"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch #46\n",
    "loss: 0.24520324\n",
    "val_loss: 0.12628034\n",
    " input:  물론이죠. 어서 타세요.\n",
    "answer:  sure . get in , please .\n",
    " model:  sure . get in , please .\n",
    "\n",
    " input:  힘 내시고, 다음 번에 다시 해 보세요.\n",
    "answer:  come on , try it again .\n",
    " model:  come on , the it again .\n",
    "\n",
    " input:  언제라도 전화하세요.\n",
    "answer:  please call me any time .\n",
    " model:  please call me any time .\n",
    "\n",
    " input:  형편에 달렸겠지요.\n",
    "answer:  that depends .\n",
    " model:  that depends .\n",
    "\n",
    " input:  불쾌한 날씨죠?\n",
    "answer:  nasty weather , isn't it ?\n",
    " model:  nasty weather , isn't it ?\n",
    "\n",
    " input:  좀 천천히 해!\n",
    "answer:  slow down a little !\n",
    " model:  slow down a little !\n",
    "\n",
    "correct:  136"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch #47\n",
    "loss: 0.23422107\n",
    "val_loss: 0.115220316\n",
    " input:  은혜는 평생 잊지 않겠습니다\n",
    "answer:  i shall never forget your kindness as long as i live .\n",
    " model:  i shall never forget your kindness as long as i live .\n",
    "\n",
    " input:  좋은 계절이 시작되는군요, 그렇죠?\n",
    "answer:  we are beginning to enjoy lovely weather , aren't we ?\n",
    " model:  we are beginning to enjoy lovely weather , aren't we ?\n",
    "\n",
    " input:  가끔 전화 주세요. \n",
    "answer:  please phone me occasionally .\n",
    " model:  please phone me occasionally .\n",
    "\n",
    " input:  비가 오고 있나요?\n",
    "answer:  is it raining now ?\n",
    " model:  is it raining now ?\n",
    "\n",
    " input:  모든 것을 다 말해 주세요.\n",
    "answer:  talk about every aspect of it .\n",
    " model:  talk about every aspect of it .\n",
    "\n",
    "correct:  148"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch #48\n",
    "loss: 0.2054679\n",
    "val_loss: 0.10596013\n",
    " input:  좋은 계절이 시작되는군요, 그렇죠?\n",
    "answer:  we are beginning to enjoy lovely weather , aren't we ?\n",
    " model:  we are beginning to enjoy lovely weather , aren't we ?\n",
    "\n",
    " input:  센트럴 공원으로 나가는 출구가 어디입니까?\n",
    "answer:  where is the exit for central park ?\n",
    " model:  where is the exit for central park ?\n",
    "\n",
    " input:  미스터 송은 가장 친한 친구중에 하나입니다.\n",
    "answer:  mr . song is one of my best friends .\n",
    " model:  mr . song is one of my best friends .\n",
    "\n",
    " input:  싹이 돋아났어요.\n",
    "answer:  the buds come out all green .\n",
    " model:  the buds come out all green .\n",
    "\n",
    " input:  30분마다 1달러씩 받습니다.\n",
    "answer:  we charge one dollar for every thirty minutes .\n",
    " model:  we charge one dollar for every thirty minutes .\n",
    "\n",
    "correct:  156"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch #52\n",
    "loss: 0.20748475\n",
    "val_loss: 0.08774358\n",
    " input:  그곳을 버스로 갈 수 있습니까?\n",
    "answer:  can i get there by bus ?\n",
    " model:  can i get there by bus ?\n",
    "\n",
    " input:  그럼, 다음에 또 뵐게요. 안녕히 계세요.\n",
    "answer:  well , see you later . good bye .\n",
    " model:  well , see you later . good bye .\n",
    "\n",
    " input:  아직 한창 나인데 세상을 떠나시다니 참 애석한 일입니다.\n",
    "answer:  it's such a pity to lose him so young .\n",
    " model:  it's such a pity to lose him so young .\n",
    "\n",
    " input:  이젠 비가 안옵니다.\n",
    "answer:  it is no longer raining .\n",
    " model:  it is no longer raining .\n",
    "\n",
    " input:  비자를 신청하려고 합니다.\n",
    "answer:  i'd like to apply for a visa .\n",
    " model:  i'd like to apply for you visa .\n",
    "\n",
    "correct:  165"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
